{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a685e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-22 18:50:04.804889: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2025-02-22 18:50:04.805435: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 18:50:04.807986: I external/local_xla/xla/tsl/cuda/cudart_stub.cc:32] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-02-22 18:50:04.815776: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1740237604.829356  258616 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1740237604.833185  258616 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-22 18:50:04.847121: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "# 1. Import Libraries\n",
    "\n",
    "# 1.1. Standard Libraries\n",
    "\n",
    "# 1.2. Third-party Libraries\n",
    "\n",
    "# Data manipulation\n",
    "import numpy as np  # Efficient array operations\n",
    "import pandas as pd  # Data structures for working with structured data\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt  # Plotting and data visualization\n",
    "import seaborn as sns  # Further data visualization\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn.preprocessing import MinMaxScaler  # Scales data to a range [0, 1]\n",
    "\n",
    "# Deep learning\n",
    "import tensorflow as tf  # Core machine learning framework\n",
    "from keras.api.models import Model  # Model class\n",
    "from keras.api.layers import Input, Dense  # Layers for the model\n",
    "\n",
    "# 1.3. Local Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0141459-855c-4fb6-b2c3-ffc6e6639c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Function Definitions\n",
    "\n",
    "# 2.1 Dataset Functions\n",
    "\n",
    "# Function to analyze a dataset\n",
    "def analyze_dataset(train_data, test_data, train_labels, test_labels):\n",
    "    \"\"\"\n",
    "    Perform a complete analysis of the dataset, including:\n",
    "    - Shape and data types\n",
    "    - Missing values\n",
    "    - Statistical summaries\n",
    "    - Feature distributions\n",
    "    - Correlation heatmap\n",
    "    - Outlier detection\n",
    "    - Label distribution\n",
    "\n",
    "    Parameters:\n",
    "        train_data (numpy.ndarray): Training feature set\n",
    "        test_data (numpy.ndarray): Testing feature set\n",
    "        train_labels (numpy.ndarray): Training labels\n",
    "        test_labels (numpy.ndarray): Testing labels\n",
    "    \"\"\"\n",
    "\n",
    "    # Convert to DataFrame for better analysis\n",
    "    train_df = pd.DataFrame(train_data)\n",
    "    test_df = pd.DataFrame(test_data)\n",
    "    train_labels_df = pd.DataFrame(train_labels, columns=[''])\n",
    "    test_labels_df = pd.DataFrame(test_labels, columns=[''])\n",
    "\n",
    "    # Dataset Shape and Data Types\n",
    "    print(\"\\n🔹 Dataset Shape & Data Types:\")\n",
    "    print(f\"Train data shape: {train_data.shape}, Type: {train_data.dtype}\")\n",
    "    print(f\"Test data shape: {test_data.shape}, Type: {test_data.dtype}\")\n",
    "    print(f\"Train labels shape: {train_labels.shape}, Type: {train_labels.dtype}\")\n",
    "    print(f\"Test labels shape: {test_labels.shape}, Type: {test_labels.dtype}\")\n",
    "\n",
    "    # Checking for Missing Values\n",
    "    print(\"\\n🔹 Missing Values:\")\n",
    "    print(f\"Train data missing values: {np.isnan(train_data).sum()}\")\n",
    "    print(f\"Test data missing values: {np.isnan(test_data).sum()}\")\n",
    "    print(f\"Train labels missing values: {np.isnan(train_labels).sum()}\")\n",
    "    print(f\"Test labels missing values: {np.isnan(test_labels).sum()}\")\n",
    "\n",
    "    # Summary Statistics (using DataFrame)\n",
    "    print(\"\\n🔹 Summary Statistics:\")\n",
    "    print(\"\\nTrain Data Statistics:\\n\\n\", train_df.describe())\n",
    "    print(\"\\nTest Data Statistics:\\n\\n\", test_df.describe())\n",
    "    print(\"\\nTrain Labels Statistics:\\n\", train_labels_df.describe())\n",
    "    print(\"\\nTest Labels Statistics:\\n\", test_labels_df.describe())\n",
    "\n",
    "    # Feature Distributions\n",
    "    num_features = train_data.shape[1]\n",
    "    plt.figure(figsize=(15, num_features * 2))\n",
    "    for i in range(num_features):\n",
    "        plt.subplot((num_features // 3) + 1, 3, i + 1)\n",
    "        sns.histplot(train_data[:, i], kde=True, bins=30, color=\"blue\", label=\"Train\")\n",
    "        sns.histplot(test_data[:, i], kde=True, bins=30, color=\"orange\", label=\"Test\")\n",
    "        plt.xlabel(f\"Feature {i}\")\n",
    "        plt.ylabel(\"Count\")\n",
    "        plt.legend()\n",
    "    plt.suptitle(\"Feature Distributions (Train vs. Test)\\n\\n\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Correlation Heatmap\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    corr_matrix = train_df.corr()\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", linewidths=0.5)\n",
    "    plt.title(\"Feature Correlation Heatmap\\n\")\n",
    "    plt.show()\n",
    "\n",
    "    # Outlier Detection (Boxplots)\n",
    "    plt.figure(figsize=(15, num_features * 2))\n",
    "    for i in range(num_features):\n",
    "        plt.subplot((num_features // 3) + 1, 3, i + 1)\n",
    "        sns.boxplot(x=train_data[:, i], color=\"red\")\n",
    "        plt.xlabel(f\"Feature {i}\")\n",
    "    plt.suptitle(\"Feature Outlier Detection (Boxplots)\\n\\n\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Label Distribution\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(train_labels, kde=True, bins=30, color=\"blue\", label=\"Train Labels\")\n",
    "    sns.histplot(test_labels, kde=True, bins=30, color=\"orange\", label=\"Test Labels\")\n",
    "    plt.xlabel(\"Labels\")\n",
    "    plt.ylabel(\"Count\")\n",
    "    plt.legend()\n",
    "    plt.title(\"Label Distribution (Train vs. Test)\\n\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eda3a561-9257-4255-a79c-1a313d637bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Load the Boston Housing dataset from Keras\n",
    "# Automatically splits into training and test sets (features and labels)\n",
    "(train_data, train_labels), (test_data, test_labels) = tf.keras.datasets.boston_housing.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8531a0ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "🔹 Dataset Shape & Data Types:\n",
      "Train data shape: (404, 13), Type: float64\n",
      "Test data shape: (102, 13), Type: float64\n",
      "Train labels shape: (404,), Type: float64\n",
      "Test labels shape: (102,), Type: float64\n",
      "\n",
      "🔹 Missing Values:\n",
      "Train data missing values: 0\n",
      "Test data missing values: 0\n",
      "Train labels missing values: 0\n",
      "Test labels missing values: 0\n",
      "\n",
      "🔹 Summary Statistics:\n",
      "\n",
      "Train Data Statistics:\n",
      "\n",
      "                0           1           2           3           4           5   \\\n",
      "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
      "mean     3.745111   11.480198   11.104431    0.061881    0.557356    6.267082   \n",
      "std      9.240734   23.767711    6.811308    0.241238    0.117293    0.709788   \n",
      "min      0.006320    0.000000    0.460000    0.000000    0.385000    3.561000   \n",
      "25%      0.081437    0.000000    5.130000    0.000000    0.453000    5.874750   \n",
      "50%      0.268880    0.000000    9.690000    0.000000    0.538000    6.198500   \n",
      "75%      3.674808   12.500000   18.100000    0.000000    0.631000    6.609000   \n",
      "max     88.976200  100.000000   27.740000    1.000000    0.871000    8.725000   \n",
      "\n",
      "               6           7           8           9           10          11  \\\n",
      "count  404.000000  404.000000  404.000000  404.000000  404.000000  404.000000   \n",
      "mean    69.010644    3.740271    9.440594  405.898515   18.475990  354.783168   \n",
      "std     27.940665    2.030215    8.698360  166.374543    2.200382   94.111148   \n",
      "min      2.900000    1.129600    1.000000  188.000000   12.600000    0.320000   \n",
      "25%     45.475000    2.077100    4.000000  279.000000   17.225000  374.672500   \n",
      "50%     78.500000    3.142300    5.000000  330.000000   19.100000  391.250000   \n",
      "75%     94.100000    5.118000   24.000000  666.000000   20.200000  396.157500   \n",
      "max    100.000000   10.710300   24.000000  711.000000   22.000000  396.900000   \n",
      "\n",
      "               12  \n",
      "count  404.000000  \n",
      "mean    12.740817  \n",
      "std      7.254545  \n",
      "min      1.730000  \n",
      "25%      6.890000  \n",
      "50%     11.395000  \n",
      "75%     17.092500  \n",
      "max     37.970000  \n",
      "\n",
      "Test Data Statistics:\n",
      "\n",
      "                0           1           2           3           4           5   \\\n",
      "count  102.000000  102.000000  102.000000  102.000000  102.000000  102.000000   \n",
      "mean     3.092336   10.901961   11.264902    0.098039    0.544156    6.354157   \n",
      "std      5.373088   21.572929    7.084148    0.298836    0.110015    0.672335   \n",
      "min      0.013110    0.000000    1.220000    0.000000    0.392000    4.880000   \n",
      "25%      0.084840    0.000000    5.455000    0.000000    0.445500    5.966000   \n",
      "50%      0.229015    0.000000    9.795000    0.000000    0.532000    6.229000   \n",
      "75%      3.779445   16.250000   18.100000    0.000000    0.609000    6.633750   \n",
      "max     25.046100   90.000000   27.740000    1.000000    0.871000    8.780000   \n",
      "\n",
      "               6           7           8           9           10          11  \\\n",
      "count  102.000000  102.000000  102.000000  102.000000  102.000000  102.000000   \n",
      "mean    66.849020    4.011982    9.980392  417.500000   18.374510  364.163333   \n",
      "std     29.034993    2.379973    8.772121  177.390477    2.026785   79.138325   \n",
      "min      6.000000    1.465500    1.000000  187.000000   13.000000   24.650000   \n",
      "25%     42.450000    2.117375    4.000000  279.250000   17.400000  377.692500   \n",
      "50%     73.750000    3.324850    5.000000  330.000000   18.900000  392.110000   \n",
      "75%     92.975000    5.276650   24.000000  666.000000   20.200000  396.780000   \n",
      "max    100.000000   12.126500   24.000000  711.000000   21.200000  396.900000   \n",
      "\n",
      "              12  \n",
      "count  102.00000  \n",
      "mean    12.30549  \n",
      "std      6.69540  \n",
      "min      1.92000  \n",
      "25%      7.30500  \n",
      "50%     11.06000  \n",
      "75%     15.91500  \n",
      "max     31.99000  \n",
      "\n",
      "Train Labels Statistics:\n",
      "                  \n",
      "count  404.000000\n",
      "mean    22.395050\n",
      "std      9.210442\n",
      "min      5.000000\n",
      "25%     16.675000\n",
      "50%     20.750000\n",
      "75%     24.800000\n",
      "max     50.000000\n",
      "\n",
      "Test Labels Statistics:\n",
      "                  \n",
      "count  102.000000\n",
      "mean    23.078431\n",
      "std      9.168863\n",
      "min      5.600000\n",
      "25%     18.650000\n",
      "50%     21.950000\n",
      "75%     27.075000\n",
      "max     50.000000\n"
     ]
    }
   ],
   "source": [
    "# 4. Use the analyze_dataset function to check the dataset\n",
    "analyze_dataset(train_data, test_data, train_labels, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9e9418d3-b387-4761-8855-aa2ff62d59bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Train Labels Shape: (404, 1)\n",
      "Test Labels Shape: (102, 1)\n",
      "\n",
      "Train Data Min: [6.3200e-03 0.0000e+00 4.6000e-01 0.0000e+00 3.8500e-01 3.5610e+00\n",
      " 2.9000e+00 1.1296e+00 1.0000e+00 1.8800e+02 1.2600e+01 3.2000e-01\n",
      " 1.7300e+00] \n",
      "Train Data Max: [ 88.9762 100.      27.74     1.       0.871    8.725  100.      10.7103\n",
      "  24.     711.      22.     396.9     37.97  ]\n",
      "Test Data Min: [1.3110e-02 0.0000e+00 1.2200e+00 0.0000e+00 3.9200e-01 4.8800e+00\n",
      " 6.0000e+00 1.4655e+00 1.0000e+00 1.8700e+02 1.3000e+01 2.4650e+01\n",
      " 1.9200e+00] \n",
      "Test Data Max: [ 25.0461  90.      27.74     1.       0.871    8.78   100.      12.1265\n",
      "  24.     711.      21.2    396.9     31.99  ]\n",
      "Train Labels Min: [5.] \n",
      "Train Labels Max: [50.]\n",
      "Test Labels Min: [5.6] \n",
      "Test Labels Max: [50.]\n",
      "\n",
      "Post-Normalization Train Data Min: [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.] \n",
      "Post-Normalization Train Data Max: [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "Post-Normalization Test Data Min: [ 7.63179629e-05  0.00000000e+00  2.78592375e-02  0.00000000e+00\n",
      "  1.44032922e-02  2.55422153e-01  3.19258496e-02  3.50600687e-02\n",
      "  0.00000000e+00 -1.91204589e-03  4.25531915e-02  6.13495386e-02\n",
      "  5.24282561e-03] \n",
      "Post-Normalization Test Data Max: [0.28144109 0.9        1.         1.         1.         1.01065066\n",
      " 1.         1.14781801 1.         1.         0.91489362 1.\n",
      " 0.83498896]\n",
      "\n",
      "Train Data Type: float32\n",
      "Test Data Type: float32\n",
      "Train Labels Type: float32\n",
      "Test Labels Type: float32\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. Preprocessing The Dataset\n",
    "\n",
    "# 5.1. Reshape Labels\n",
    "\n",
    "# Convert labels to a 2D array with shape (-1, 1) to ensure compatibility with models\n",
    "train_labels = np.reshape(train_labels, newshape=(-1, 1))\n",
    "test_labels = np.reshape(test_labels, newshape=(-1, 1))\n",
    "print(\"\\nTrain Labels Shape:\", train_labels.shape)\n",
    "print(\"Test Labels Shape:\", test_labels.shape)\n",
    "\n",
    "# 5.2 Normalize Data using Min-Max Scaling\n",
    "\n",
    "# Check min/max values for each set of data\n",
    "train_data_min, train_data_max = train_data.min(axis=0), train_data.max(axis=0)\n",
    "test_data_min, test_data_max = test_data.min(axis=0), test_data.max(axis=0)\n",
    "train_labels_min, train_labels_max = train_labels.min(axis=0), train_labels.max(axis=0)\n",
    "test_labels_min, test_labels_max = test_labels.min(axis=0), test_labels.max(axis=0)\n",
    "print(\"\\nTrain Data Min:\", train_data_min, \"\\nTrain Data Max:\", train_data_max)\n",
    "print(\"Test Data Min:\", test_data_min, \"\\nTest Data Max:\", test_data_max)\n",
    "print(\"Train Labels Min:\", train_labels_min, \"\\nTrain Labels Max:\", train_labels_max)\n",
    "print(\"Test Labels Min:\", test_labels_min, \"\\nTest Labels Max:\", test_labels_max)\n",
    "\n",
    "# Fit the scaler on training data\n",
    "min_max_scaler = MinMaxScaler()\n",
    "min_max_scaler.fit(train_data)\n",
    "\n",
    "# Transform both training and test data\n",
    "train_data = min_max_scaler.transform(train_data)\n",
    "test_data = min_max_scaler.transform(test_data)\n",
    "\n",
    "# Check min/max values for training and test data after normalization\n",
    "train_min_post, train_max_post = train_data.min(axis=0), train_data.max(axis=0)\n",
    "test_min_post, test_max_post = test_data.min(axis=0), test_data.max(axis=0)\n",
    "print(\"\\nPost-Normalization Train Data Min:\", train_min_post, \"\\nPost-Normalization Train Data Max:\", train_max_post)\n",
    "print(\"Post-Normalization Test Data Min:\", test_min_post, \"\\nPost-Normalization Test Data Max:\", test_max_post)\n",
    "\n",
    "# 5.3. Change Data Types\n",
    "\n",
    "# Convert dataset values to float32tra to optimize memory usage and computation speed\n",
    "train_data = train_data.astype(np.float32)\n",
    "test_data = test_data.astype(np.float32)\n",
    "train_labels = train_labels.astype(np.float32)\n",
    "test_labels = test_labels.astype(np.float32)\n",
    "print(\"\\nTrain Data Type:\", train_data.dtype)\n",
    "print(\"Test Data Type:\", test_data.dtype)\n",
    "print(\"Train Labels Type:\", train_labels.dtype)\n",
    "print(\"Test Labels Type:\", test_labels.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea8ddf4f-51d8-4cd4-be99-10a6a9aa6f00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1740237608.266103  258616 gpu_device.cc:2344] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">56</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │             <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │            \u001b[38;5;34m56\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │             \u001b[38;5;34m5\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">61</span> (244.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m61\u001b[0m (244.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 6. Create regression model\n",
    "\n",
    "# Define input layer\n",
    "input_layer = Input(shape=(13,))\n",
    "\n",
    "# Hidden layers with ReLU activation\n",
    "first_layer = Dense(units=4, activation=\"relu\")(input_layer)\n",
    "\n",
    "# Output layer (regression, so no activation)\n",
    "output_layer = Dense(units=1)(first_layer)\n",
    "\n",
    "# Define model using Functional API\n",
    "regression_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "# Display model summary\n",
    "regression_model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
