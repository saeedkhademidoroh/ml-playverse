
ğŸ“œ  Logging experiment output:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log/log_2025-05-24_15-23-55.txt

ğŸ¯  _load_previous_results

âš™ï¸   Piplining experiment 1/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m0_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)       â”ƒ Output Shape â”ƒ Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer        â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (InputLayer)       â”‚ 32, 3)       â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d (Conv2D)    â”‚ (None, 32,   â”‚     896 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_1 (Conv2D)  â”‚ (None, 32,   â”‚   9,248 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d      â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_2 (Conv2D)  â”‚ (None, 16,   â”‚  18,496 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_3 (Conv2D)  â”‚ (None, 16,   â”‚  36,928 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_1    â”‚ (None, 8, 8, â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 64)          â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten (Flatten)  â”‚ (None, 4096) â”‚       0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense (Dense)      â”‚ (None, 128)  â”‚ 524,416 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout (Dropout)  â”‚ (None, 128)  â”‚       0 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_1 (Dense)    â”‚ (None, 10)   â”‚   1,290 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 591,274 (2.26 MB)
 Trainable params: 591,274 (2.26 MB)
 Non-trainable params: 0 (0.00 B)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.08500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m0_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m0_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:24

200/200 - 8s - 38ms/step - accuracy: 0.0812 - loss: 2.5248 - val_accuracy: 0.0850 - val_loss: 2.3821 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy did not improve from 0.08500

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m0_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:24

200/200 - 6s - 29ms/step - accuracy: 0.1025 - loss: 2.3547 - val_accuracy: 0.0700 - val_loss: 2.3478 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy did not improve from 0.08500

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m0_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:24

200/200 - 7s - 33ms/step - accuracy: 0.1013 - loss: 2.3276 - val_accuracy: 0.0700 - val_loss: 2.3354 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.08500

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m0_r1_default/epoch_04.keras

Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:24

200/200 - 5s - 26ms/step - accuracy: 0.0850 - loss: 2.3181 - val_accuracy: 0.0700 - val_loss: 2.3247 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 0,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:24:30",
    "duration": "0:00:35",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.3180549144744873,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.10249999910593033,
    "max_train_acc_epoch": 2,
    "min_val_loss": 2.3246512413024902,
    "min_val_loss_epoch": 4,
    "max_val_acc": 0.08500000089406967,
    "max_val_acc_epoch": 1,
    "final_test_loss": 2.3801028728485107,
    "final_test_acc": 0.10000000149011612
  }
]

âœ…   m0 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 2/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m1_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_1"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)       â”ƒ Output Shape â”ƒ Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_1      â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (InputLayer)       â”‚ 32, 3)       â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_4 (Conv2D)  â”‚ (None, 32,   â”‚     896 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation         â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_5 (Conv2D)  â”‚ (None, 32,   â”‚   9,248 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_1       â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_2    â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_6 (Conv2D)  â”‚ (None, 16,   â”‚  18,496 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     256 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_2       â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_7 (Conv2D)  â”‚ (None, 16,   â”‚  36,928 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     256 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_3       â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_3    â”‚ (None, 8, 8, â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 64)          â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ flatten_1          â”‚ (None, 4096) â”‚       0 â”‚
â”‚ (Flatten)          â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_2 (Dense)    â”‚ (None, 128)  â”‚ 524,416 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_1          â”‚ (None, 128)  â”‚       0 â”‚
â”‚ (Dropout)          â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_3 (Dense)    â”‚ (None, 10)   â”‚   1,290 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 592,042 (2.26 MB)
 Trainable params: 591,658 (2.26 MB)
 Non-trainable params: 384 (1.50 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.14500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m1_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m1_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:24

200/200 - 9s - 46ms/step - accuracy: 0.1375 - loss: 6.0340 - val_accuracy: 0.1450 - val_loss: 2.8865 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy improved from 0.14500 to 0.17000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m1_r1_default/best.keras

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m1_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:24

200/200 - 5s - 24ms/step - accuracy: 0.1500 - loss: 2.7470 - val_accuracy: 0.1700 - val_loss: 2.7725 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy did not improve from 0.17000

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m1_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:25

200/200 - 5s - 23ms/step - accuracy: 0.1762 - loss: 2.5536 - val_accuracy: 0.1250 - val_loss: 2.5566 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.17000

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m1_r1_default/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:25

200/200 - 5s - 23ms/step - accuracy: 0.1488 - loss: 2.4796 - val_accuracy: 0.1250 - val_loss: 2.4903 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 2.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 1,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:25:06",
    "duration": "0:00:36",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.4795827865600586,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.17624999582767487,
    "max_train_acc_epoch": 3,
    "min_val_loss": 2.4903156757354736,
    "min_val_loss_epoch": 4,
    "max_val_acc": 0.17000000178813934,
    "max_val_acc_epoch": 2,
    "final_test_loss": 6.459811210632324,
    "final_test_acc": 0.15000000596046448
  }
]

âœ…   m1 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 3/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m2_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_2"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)       â”ƒ Output Shape â”ƒ Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_2      â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (InputLayer)       â”‚ 32, 3)       â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_8 (Conv2D)  â”‚ (None, 32,   â”‚     448 â”‚
â”‚                    â”‚ 32, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚      64 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_4       â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_9 (Conv2D)  â”‚ (None, 32,   â”‚   2,320 â”‚
â”‚                    â”‚ 32, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚      64 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_5       â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_4    â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 16, 16)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_10 (Conv2D) â”‚ (None, 16,   â”‚   4,640 â”‚
â”‚                    â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_6       â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_11 (Conv2D) â”‚ (None, 16,   â”‚   9,248 â”‚
â”‚                    â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_7       â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_5    â”‚ (None, 8, 8, â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 32)          â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_poâ€¦ â”‚ (None, 32)   â”‚       0 â”‚
â”‚ (GlobalAveragePooâ€¦ â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_2          â”‚ (None, 32)   â”‚       0 â”‚
â”‚ (Dropout)          â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_4 (Dense)    â”‚ (None, 10)   â”‚     330 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 17,370 (67.85 KB)
 Trainable params: 17,178 (67.10 KB)
 Non-trainable params: 192 (768.00 B)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.12500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:25

200/200 - 4s - 21ms/step - accuracy: 0.1450 - loss: 2.4629 - val_accuracy: 0.1250 - val_loss: 2.4194 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy improved from 0.12500 to 0.17000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/best.keras

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:25

200/200 - 2s - 11ms/step - accuracy: 0.1600 - loss: 2.2889 - val_accuracy: 0.1700 - val_loss: 2.2434 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy improved from 0.17000 to 0.18500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/best.keras

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:25

200/200 - 2s - 11ms/step - accuracy: 0.1875 - loss: 2.2593 - val_accuracy: 0.1850 - val_loss: 2.1723 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.18500

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m2_r1_default/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:25

200/200 - 2s - 10ms/step - accuracy: 0.1575 - loss: 2.2344 - val_accuracy: 0.0900 - val_loss: 3.7343 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 3.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 2,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:25:21",
    "duration": "0:00:14",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.2343873977661133,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.1875,
    "max_train_acc_epoch": 3,
    "min_val_loss": 2.1723272800445557,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.1850000023841858,
    "max_val_acc_epoch": 3,
    "final_test_loss": 3.937009334564209,
    "final_test_acc": 0.1850000023841858
  }
]

âœ…   m2 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 4/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m3_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_3"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)       â”ƒ Output Shape â”ƒ Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_3      â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (InputLayer)       â”‚ 32, 3)       â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_12 (Conv2D) â”‚ (None, 32,   â”‚     896 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_8       â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_13 (Conv2D) â”‚ (None, 32,   â”‚   9,248 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_9       â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_6    â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_14 (Conv2D) â”‚ (None, 16,   â”‚  18,496 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     256 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_10      â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_15 (Conv2D) â”‚ (None, 16,   â”‚  36,928 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     256 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_11      â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_7    â”‚ (None, 8, 8, â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 64)          â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_poâ€¦ â”‚ (None, 64)   â”‚       0 â”‚
â”‚ (GlobalAveragePooâ€¦ â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_3          â”‚ (None, 64)   â”‚       0 â”‚
â”‚ (Dropout)          â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_5 (Dense)    â”‚ (None, 10)   â”‚     650 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 66,986 (261.66 KB)
 Trainable params: 66,602 (260.16 KB)
 Non-trainable params: 384 (1.50 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.12500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m3_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m3_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:25

200/200 - 6s - 30ms/step - accuracy: 0.1462 - loss: 2.6085 - val_accuracy: 0.1250 - val_loss: 2.5687 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy did not improve from 0.12500

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m3_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:25

200/200 - 4s - 18ms/step - accuracy: 0.1412 - loss: 2.3995 - val_accuracy: 0.0900 - val_loss: 2.3796 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy improved from 0.12500 to 0.16500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m3_r1_default/best.keras

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m3_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:25

200/200 - 4s - 18ms/step - accuracy: 0.1850 - loss: 2.2918 - val_accuracy: 0.1650 - val_loss: 2.5848 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.16500

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m3_r1_default/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:25

200/200 - 4s - 18ms/step - accuracy: 0.1700 - loss: 2.2574 - val_accuracy: 0.1400 - val_loss: 2.7630 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 3.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 3,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:25:41",
    "duration": "0:00:20",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.2573792934417725,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.1850000023841858,
    "max_train_acc_epoch": 3,
    "min_val_loss": 2.3795993328094482,
    "min_val_loss_epoch": 2,
    "max_val_acc": 0.16500000655651093,
    "max_val_acc_epoch": 3,
    "final_test_loss": 4.871713161468506,
    "final_test_acc": 0.125
  }
]

âœ…   m3 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 5/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m4_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_4"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer (type)       â”ƒ Output Shape â”ƒ Param # â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layer_4      â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (InputLayer)       â”‚ 32, 3)       â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ depthwise_conv2d   â”‚ (None, 32,   â”‚      30 â”‚
â”‚ (DepthwiseConv2D)  â”‚ 32, 3)       â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_16 (Conv2D) â”‚ (None, 32,   â”‚     128 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_12      â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ depthwise_conv2d_1 â”‚ (None, 32,   â”‚     320 â”‚
â”‚ (DepthwiseConv2D)  â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_17 (Conv2D) â”‚ (None, 32,   â”‚   1,056 â”‚
â”‚                    â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 32,   â”‚     128 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_13      â”‚ (None, 32,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 32, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_8    â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ depthwise_conv2d_2 â”‚ (None, 16,   â”‚     320 â”‚
â”‚ (DepthwiseConv2D)  â”‚ 16, 32)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_18 (Conv2D) â”‚ (None, 16,   â”‚   2,112 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     256 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_14      â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ depthwise_conv2d_3 â”‚ (None, 16,   â”‚     640 â”‚
â”‚ (DepthwiseConv2D)  â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_19 (Conv2D) â”‚ (None, 16,   â”‚   4,160 â”‚
â”‚                    â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normalizatiâ€¦ â”‚ (None, 16,   â”‚     256 â”‚
â”‚ (BatchNormalizatiâ€¦ â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activation_15      â”‚ (None, 16,   â”‚       0 â”‚
â”‚ (Activation)       â”‚ 16, 64)      â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_pooling2d_9    â”‚ (None, 8, 8, â”‚       0 â”‚
â”‚ (MaxPooling2D)     â”‚ 64)          â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_average_poâ€¦ â”‚ (None, 64)   â”‚       0 â”‚
â”‚ (GlobalAveragePooâ€¦ â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_4          â”‚ (None, 64)   â”‚       0 â”‚
â”‚ (Dropout)          â”‚              â”‚         â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_6 (Dense)    â”‚ (None, 10)   â”‚     650 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 10,184 (39.78 KB)
 Trainable params: 9,800 (38.28 KB)
 Non-trainable params: 384 (1.50 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.09500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:25

200/200 - 6s - 32ms/step - accuracy: 0.1375 - loss: 2.5323 - val_accuracy: 0.0950 - val_loss: 2.4759 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy improved from 0.09500 to 0.12500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/best.keras

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:25

200/200 - 3s - 14ms/step - accuracy: 0.1725 - loss: 2.3294 - val_accuracy: 0.1250 - val_loss: 2.7504 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy improved from 0.12500 to 0.14500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/best.keras

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:25

200/200 - 3s - 14ms/step - accuracy: 0.1637 - loss: 2.2430 - val_accuracy: 0.1450 - val_loss: 3.7018 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy improved from 0.14500 to 0.20000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/best.keras

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m4_r1_default/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:25

200/200 - 3s - 14ms/step - accuracy: 0.1950 - loss: 2.2226 - val_accuracy: 0.2000 - val_loss: 2.0848 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 4.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 4,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:25:59",
    "duration": "0:00:17",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.222644090652466,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.19499999284744263,
    "max_train_acc_epoch": 4,
    "min_val_loss": 2.084770441055298,
    "min_val_loss_epoch": 4,
    "max_val_acc": 0.20000000298023224,
    "max_val_acc_epoch": 4,
    "final_test_loss": 5.725679874420166,
    "final_test_acc": 0.12999999523162842
  }
]

âœ…   m4 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 6/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m5_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_5"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer       â”ƒ Output    â”ƒ Parâ€¦ â”ƒ Connected  â”ƒ
â”ƒ (type)      â”ƒ Shape     â”ƒ    # â”ƒ to         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layeâ€¦ â”‚ (None,    â”‚    0 â”‚ -          â”‚
â”‚ (InputLayeâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 3)        â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_21   â”‚ (None,    â”‚  896 â”‚ input_layâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_21â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_22   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_22â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_20   â”‚ (None,    â”‚  128 â”‚ input_layâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add (Add)   â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 32, 32,   â”‚      â”‚ conv2d_20â€¦ â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add[0][0]  â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_poolinâ€¦ â”‚ (None,    â”‚    0 â”‚ activatioâ€¦ â”‚
â”‚ (MaxPoolinâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_24   â”‚ (None,    â”‚ 18,â€¦ â”‚ max_pooliâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  256 â”‚ conv2d_24â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_25   â”‚ (None,    â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  256 â”‚ conv2d_25â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_23   â”‚ (None,    â”‚ 2,1â€¦ â”‚ max_pooliâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_1 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 16, 16,   â”‚      â”‚ conv2d_23â€¦ â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_1[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ max_poolinâ€¦ â”‚ (None, 8, â”‚    0 â”‚ activatioâ€¦ â”‚
â”‚ (MaxPoolinâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_aveâ€¦ â”‚ (None,    â”‚    0 â”‚ max_pooliâ€¦ â”‚
â”‚ (GlobalAveâ€¦ â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_5   â”‚ (None,    â”‚    0 â”‚ global_avâ€¦ â”‚
â”‚ (Dropout)   â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_7     â”‚ (None,    â”‚  650 â”‚ dropout_5â€¦ â”‚
â”‚ (Dense)     â”‚ 10)       â”‚      â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 69,226 (270.41 KB)
 Trainable params: 68,842 (268.91 KB)
 Non-trainable params: 384 (1.50 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.15500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m5_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m5_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:26

200/200 - 8s - 41ms/step - accuracy: 0.1338 - loss: 2.5586 - val_accuracy: 0.1550 - val_loss: 2.4619 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy did not improve from 0.15500

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m5_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:26

200/200 - 5s - 27ms/step - accuracy: 0.1475 - loss: 2.4130 - val_accuracy: 0.1150 - val_loss: 2.6104 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy did not improve from 0.15500

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m5_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:26

200/200 - 4s - 22ms/step - accuracy: 0.1612 - loss: 2.3583 - val_accuracy: 0.1150 - val_loss: 2.4059 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.15500

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m5_r1_default/epoch_04.keras

Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:26

200/200 - 5s - 23ms/step - accuracy: 0.1488 - loss: 2.3213 - val_accuracy: 0.1550 - val_loss: 2.3035 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 1.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 5,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:26:24",
    "duration": "0:00:25",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.3213114738464355,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.16124999523162842,
    "max_train_acc_epoch": 3,
    "min_val_loss": 2.3035194873809814,
    "min_val_loss_epoch": 4,
    "max_val_acc": 0.1550000011920929,
    "max_val_acc_epoch": 1,
    "final_test_loss": 6.05612325668335,
    "final_test_acc": 0.08500000089406967
  }
]

âœ…   m5 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 7/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m6_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _standardize

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_6"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer       â”ƒ Output    â”ƒ Parâ€¦ â”ƒ Connected  â”ƒ
â”ƒ (type)      â”ƒ Shape     â”ƒ    # â”ƒ to         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layeâ€¦ â”‚ (None,    â”‚    0 â”‚ -          â”‚
â”‚ (InputLayeâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 3)        â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_26   â”‚ (None,    â”‚  896 â”‚ input_layâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_26â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_27   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_27â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_28   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_28â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_2 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_2[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_29   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_29â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_30   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_30â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_3 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_3[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_32   â”‚ (None,    â”‚ 18,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  256 â”‚ conv2d_32â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_33   â”‚ (None,    â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  256 â”‚ conv2d_33â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_31   â”‚ (None,    â”‚ 2,1â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_4 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 16, 16,   â”‚      â”‚ conv2d_31â€¦ â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_4[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_34   â”‚ (None,    â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  256 â”‚ conv2d_34â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_35   â”‚ (None,    â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  256 â”‚ conv2d_35â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_5 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 16, 16,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_5[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_37   â”‚ (None, 8, â”‚ 73,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  512 â”‚ conv2d_37â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_38   â”‚ (None, 8, â”‚ 147â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  512 â”‚ conv2d_38â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_36   â”‚ (None, 8, â”‚ 8,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_6 (Add) â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 8, 128)   â”‚      â”‚ conv2d_36â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_6[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_39   â”‚ (None, 8, â”‚ 147â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  512 â”‚ conv2d_39â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_40   â”‚ (None, 8, â”‚ 147â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  512 â”‚ conv2d_40â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_7 (Add) â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 8, 128)   â”‚      â”‚ activatioâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_7[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 128)   â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_aveâ€¦ â”‚ (None,    â”‚    0 â”‚ activatioâ€¦ â”‚
â”‚ (GlobalAveâ€¦ â”‚ 128)      â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_6   â”‚ (None,    â”‚    0 â”‚ global_avâ€¦ â”‚
â”‚ (Dropout)   â”‚ 128)      â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_8     â”‚ (None,    â”‚ 1,2â€¦ â”‚ dropout_6â€¦ â”‚
â”‚ (Dense)     â”‚ 10)       â”‚      â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 699,210 (2.67 MB)
 Trainable params: 697,354 (2.66 MB)
 Non-trainable params: 1,856 (7.25 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.07000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:26

200/200 - 18s - 89ms/step - accuracy: 0.1100 - loss: 3.7022 - val_accuracy: 0.0700 - val_loss: 3.0639 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy improved from 0.07000 to 0.09500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/best.keras

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:26

200/200 - 12s - 62ms/step - accuracy: 0.1075 - loss: 2.9805 - val_accuracy: 0.0950 - val_loss: 2.7713 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy improved from 0.09500 to 0.11500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/best.keras

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:27

200/200 - 12s - 62ms/step - accuracy: 0.1150 - loss: 2.7130 - val_accuracy: 0.1150 - val_loss: 2.6197 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.11500

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m6_r1_default/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:27

200/200 - 11s - 57ms/step - accuracy: 0.1300 - loss: 2.6535 - val_accuracy: 0.1150 - val_loss: 2.9976 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 3.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 6,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:27:23",
    "duration": "0:00:58",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.653496503829956,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.12999999523162842,
    "max_train_acc_epoch": 4,
    "min_val_loss": 2.619711399078369,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.11500000208616257,
    "max_val_acc_epoch": 3,
    "final_test_loss": 37.214420318603516,
    "final_test_acc": 0.10000000149011612
  }
]

âœ…   m6 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 8/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m7_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  _standardize

ğŸ¯  _augment_dataset

ğŸ¯  build_model

Model: "functional_7"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer       â”ƒ Output    â”ƒ Parâ€¦ â”ƒ Connected  â”ƒ
â”ƒ (type)      â”ƒ Shape     â”ƒ    # â”ƒ to         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layeâ€¦ â”‚ (None,    â”‚    0 â”‚ -          â”‚
â”‚ (InputLayeâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 3)        â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_41   â”‚ (None,    â”‚  560 â”‚ input_layâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_41â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_42   â”‚ (None,    â”‚ 3,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_42â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_43   â”‚ (None,    â”‚ 3,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_43â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_8 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_8[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_44   â”‚ (None,    â”‚ 3,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_44â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_45   â”‚ (None,    â”‚ 3,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_45â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_9 (Add) â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚             â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_9[0][â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_46   â”‚ (None,    â”‚ 3,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_46â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_47   â”‚ (None,    â”‚ 3,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   80 â”‚ conv2d_47â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_10      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_10[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 20)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_48   â”‚ (None,    â”‚ 7,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  160 â”‚ conv2d_48â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_49   â”‚ (None,    â”‚ 14,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  160 â”‚ conv2d_49â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_50   â”‚ (None,    â”‚  840 â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_11      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 16, 16,   â”‚      â”‚ conv2d_50â€¦ â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_11[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_51   â”‚ (None,    â”‚ 14,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  160 â”‚ conv2d_51â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_52   â”‚ (None,    â”‚ 14,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  160 â”‚ conv2d_52â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_12      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 16, 16,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_12[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_53   â”‚ (None,    â”‚ 14,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  160 â”‚ conv2d_53â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_54   â”‚ (None,    â”‚ 14,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  160 â”‚ conv2d_54â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_13      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 16, 16,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_13[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 40)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_55   â”‚ (None, 8, â”‚ 28,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  320 â”‚ conv2d_55â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_56   â”‚ (None, 8, â”‚ 57,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  320 â”‚ conv2d_56â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_57   â”‚ (None, 8, â”‚ 3,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_14      â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 8, 80)    â”‚      â”‚ conv2d_57â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_14[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_58   â”‚ (None, 8, â”‚ 57,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  320 â”‚ conv2d_58â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_59   â”‚ (None, 8, â”‚ 57,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  320 â”‚ conv2d_59â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_15      â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 8, 80)    â”‚      â”‚ activatioâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_15[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_60   â”‚ (None, 8, â”‚ 57,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  320 â”‚ conv2d_60â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_61   â”‚ (None, 8, â”‚ 57,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  320 â”‚ conv2d_61â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_16      â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 8, 80)    â”‚      â”‚ activatioâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_16[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 80)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_aveâ€¦ â”‚ (None,    â”‚    0 â”‚ activatioâ€¦ â”‚
â”‚ (GlobalAveâ€¦ â”‚ 80)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dropout_7   â”‚ (None,    â”‚    0 â”‚ global_avâ€¦ â”‚
â”‚ (Dropout)   â”‚ 80)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_9     â”‚ (None,    â”‚  810 â”‚ dropout_7â€¦ â”‚
â”‚ (Dense)     â”‚ 10)       â”‚      â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 427,370 (1.63 MB)
 Trainable params: 425,650 (1.62 MB)
 Non-trainable params: 1,720 (6.72 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.11000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m7_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m7_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:27

200/200 - 20s - 100ms/step - accuracy: 0.1037 - loss: 3.5295 - val_accuracy: 0.1100 - val_loss: 4.1563 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy did not improve from 0.11000

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m7_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:28

200/200 - 9s - 46ms/step - accuracy: 0.1138 - loss: 2.8384 - val_accuracy: 0.0950 - val_loss: 2.7388 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy improved from 0.11000 to 0.11500, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m7_r1_default/best.keras

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m7_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:28

200/200 - 9s - 43ms/step - accuracy: 0.0962 - loss: 2.7163 - val_accuracy: 0.1150 - val_loss: 2.6370 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.11500

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m7_r1_default/epoch_04.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:28

200/200 - 9s - 44ms/step - accuracy: 0.1013 - loss: 2.6599 - val_accuracy: 0.0700 - val_loss: 2.6751 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 3.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 7,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:28:23",
    "duration": "0:01:00",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.6599011421203613,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.11375000327825546,
    "max_train_acc_epoch": 2,
    "min_val_loss": 2.637030839920044,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.11500000208616257,
    "max_val_acc_epoch": 3,
    "final_test_loss": 2.608859062194824,
    "final_test_acc": 0.16500000655651093
  }
]

âœ…   m7 run 1 with 'default' successfully executed

âš™ï¸   Piplining experiment 9/9

ğŸ¯  _run_single_pipeline_entry

ğŸ¯  load_config

ğŸ“‚  Loading configuration file:
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/config/default.json

ğŸ¯  _ensure_output_directories

ğŸ“‚  Ensuring output directories
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/log
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/result
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/model
/home/saeed/projects/ml/src/ml-playverse/cifar/artifact/error

ğŸš€  Launching experiment m8_r1 with 'default'

ğŸ¯  load_dataset
Files already downloaded and verified
Files already downloaded and verified

ğŸ¯  build_model

Model: "functional_8"
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”“
â”ƒ Layer       â”ƒ Output    â”ƒ Parâ€¦ â”ƒ Connected  â”ƒ
â”ƒ (type)      â”ƒ Shape     â”ƒ    # â”ƒ to         â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”©
â”‚ input_layeâ€¦ â”‚ (None,    â”‚    0 â”‚ -          â”‚
â”‚ (InputLayeâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 3)        â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_62   â”‚ (None,    â”‚  448 â”‚ input_layâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_62â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_63   â”‚ (None,    â”‚ 2,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_63â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_64   â”‚ (None,    â”‚ 2,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_64â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_17      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_17[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_65   â”‚ (None,    â”‚ 2,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_65â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_66   â”‚ (None,    â”‚ 2,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_66â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_18      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_18[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_67   â”‚ (None,    â”‚ 2,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_67â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_68   â”‚ (None,    â”‚ 2,3â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚   64 â”‚ conv2d_68â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_19      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 32, 32,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_19[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 32, 32,   â”‚      â”‚            â”‚
â”‚             â”‚ 16)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_69   â”‚ (None,    â”‚ 4,6â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_69â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_70   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_70â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_71   â”‚ (None,    â”‚  544 â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_20      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 16, 16,   â”‚      â”‚ conv2d_71â€¦ â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_20[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_72   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_72â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_73   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_73â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_21      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 16, 16,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_21[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_74   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_74â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_75   â”‚ (None,    â”‚ 9,2â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None,    â”‚  128 â”‚ conv2d_75â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_22      â”‚ (None,    â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 16, 16,   â”‚      â”‚ activatioâ€¦ â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None,    â”‚    0 â”‚ add_22[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 16, 16,   â”‚      â”‚            â”‚
â”‚             â”‚ 32)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_76   â”‚ (None, 8, â”‚ 18,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  256 â”‚ conv2d_76â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_77   â”‚ (None, 8, â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  256 â”‚ conv2d_77â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_78   â”‚ (None, 8, â”‚ 2,1â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_23      â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 8, 64)    â”‚      â”‚ conv2d_78â€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_23[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_79   â”‚ (None, 8, â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  256 â”‚ conv2d_79â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_80   â”‚ (None, 8, â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  256 â”‚ conv2d_80â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_24      â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 8, 64)    â”‚      â”‚ activatioâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_24[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_81   â”‚ (None, 8, â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  256 â”‚ conv2d_81â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ conv2d_82   â”‚ (None, 8, â”‚ 36,â€¦ â”‚ activatioâ€¦ â”‚
â”‚ (Conv2D)    â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ batch_normâ€¦ â”‚ (None, 8, â”‚  256 â”‚ conv2d_82â€¦ â”‚
â”‚ (BatchNormâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ add_25      â”‚ (None, 8, â”‚    0 â”‚ batch_norâ€¦ â”‚
â”‚ (Add)       â”‚ 8, 64)    â”‚      â”‚ activatioâ€¦ â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ activationâ€¦ â”‚ (None, 8, â”‚    0 â”‚ add_25[0]â€¦ â”‚
â”‚ (Activatioâ€¦ â”‚ 8, 64)    â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ global_aveâ€¦ â”‚ (None,    â”‚    0 â”‚ activatioâ€¦ â”‚
â”‚ (GlobalAveâ€¦ â”‚ 64)       â”‚      â”‚            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚ dense_10    â”‚ (None,    â”‚  650 â”‚ global_avâ€¦ â”‚
â”‚ (Dense)     â”‚ 10)       â”‚      â”‚            â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
 Total params: 274,442 (1.05 MB)
 Trainable params: 273,066 (1.04 MB)
 Non-trainable params: 1,376 (5.38 KB)

ğŸ¯  train_model

ğŸ¯  _resume_from_checkpoint

ğŸ¯  _load_from_checkpoint

ğŸ¯  _split_dataset

ğŸ¯  _prepare_checkpoint_callback

ğŸ¯  __init__ (RecoveryCheckpoint)

ğŸ§   Printing training configuration:
Light Mode:       ON
Augmentation:     ON
L2 Regularization: ON (Î»=0.0005)
Dropout:           ON (rate=0.5)
Optimizer:         adam (lr=0.01)
Momentum:          0.9
LR Scheduler:      ON
Early Stopping:    ON
Epochs:            4
Batch Size:        4

Epoch 1/4

Epoch 1: val_accuracy improved from -inf to 0.08000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m8_r1_default/best.keras

Epoch 1: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m8_r1_default/epoch_01.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_1

ğŸ•’  Recording time at 15:28

200/200 - 19s - 93ms/step - accuracy: 0.1100 - loss: 3.0258 - val_accuracy: 0.0800 - val_loss: 65.1387 - learning_rate: 0.0100
Epoch 2/4

Epoch 2: val_accuracy improved from 0.08000 to 0.16000, saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m8_r1_default/best.keras

Epoch 2: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m8_r1_default/epoch_02.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_2

ğŸ•’  Recording time at 15:28

200/200 - 7s - 35ms/step - accuracy: 0.1475 - loss: 2.6561 - val_accuracy: 0.1600 - val_loss: 2.8471 - learning_rate: 0.0100
Epoch 3/4

Epoch 3: val_accuracy did not improve from 0.16000

Epoch 3: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m8_r1_default/epoch_03.keras

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_3

ğŸ•’  Recording time at 15:29

200/200 - 7s - 33ms/step - accuracy: 0.1650 - loss: 2.4636 - val_accuracy: 0.1600 - val_loss: 2.5737 - learning_rate: 0.0100
Epoch 4/4

Epoch 4: val_accuracy did not improve from 0.16000

Epoch 4: saving model to /home/saeed/projects/ml/src/ml-playverse/cifar/artifact/checkpoint/m8_r1_default/epoch_04.keras

Epoch 4: ReduceLROnPlateau reducing learning rate to 0.004999999888241291.

ğŸ¯  on_epoch_end

ğŸ’¾  Checkpointing experiment at epoch_4

ğŸ•’  Recording time at 15:29

200/200 - 7s - 33ms/step - accuracy: 0.1575 - loss: 2.4208 - val_accuracy: 0.0700 - val_loss: 6.9690 - learning_rate: 0.0100
Restoring model weights from the end of the best epoch: 2.

ğŸ¯  _save_training_history

ğŸ¯  extract_history_metrics

ğŸ¯  _create_evaluation_dictionary

ğŸ“Š  Dumping experiment results:
[
  {
    "model": 8,
    "run": 1,
    "config": "default",
    "date": "2025-05-24",
    "time": "15:29:08",
    "duration": "0:00:45",
    "parameters": {
      "LIGHT_MODE": true,
      "AUGMENT_MODE": true,
      "L2_MODE": {
        "enabled": true,
        "lambda": 0.0005
      },
      "DROPOUT_MODE": {
        "enabled": true,
        "rate": 0.5
      },
      "OPTIMIZER": {
        "type": "adam",
        "learning_rate": 0.01,
        "momentum": 0.9
      },
      "SCHEDULE_MODE": true,
      "EARLY_STOP_MODE": true,
      "EPOCHS_COUNT": 4,
      "BATCH_SIZE": 4
    },
    "min_train_loss": 2.4207825660705566,
    "min_train_loss_epoch": 4,
    "max_train_acc": 0.16500000655651093,
    "max_train_acc_epoch": 3,
    "min_val_loss": 2.5736632347106934,
    "min_val_loss_epoch": 3,
    "max_val_acc": 0.1599999964237213,
    "max_val_acc_epoch": 2,
    "final_test_loss": 3.08827543258667,
    "final_test_acc": 0.20999999344348907
  }
]

âœ…   m8 run 1 with 'default' successfully executed
